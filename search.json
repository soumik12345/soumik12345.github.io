[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "About this blog\n\n\n\n\n\n\n\n\n  \n\n\n\n\nDepthwise Separable Convolutions in Deep Learning\n\n\n\n\n\n\n\nalgebra\n\n\ncnn\n\n\ncomputervision\n\n\nconvolution\n\n\nDeepLearning\n\n\ndepthwiseseperableconvolution\n\n\ndnn\n\n\nembeddeddevices\n\n\ngoogle\n\n\nmathematics\n\n\nmaths\n\n\nmobiledevices\n\n\nmobilenet\n\n\nneural-networks\n\n\nplotly\n\n\npython\n\n\nxception\n\n\n\n\nMany modern CNN architectures such as Xception and Mobilenet make use of Depthwise Seperable Convolution to make them fast enough to run on mobile devices\n\n\n\n\n\n\nOct 19, 2019\n\n\nGeekyRakshit\n\n\n\n\n\n\n  \n\n\n\n\nNearest Celebrity Face using Deep Learning\n\n\n\n\n\n\n\ncomputervision\n\n\ndeeplearning\n\n\nfacenet\n\n\ninception\n\n\nkeras\n\n\nnearestcelebrityface\n\n\npython\n\n\ntensorflow\n\n\n\n\nDeep Learning Techniques used to verify and recognize faces can also be extended to replicate Facebook apps saying which celebrity do you look like\n\n\n\n\n\n\nAug 7, 2019\n\n\nGeekyRakshit\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geekyrakshit",
    "section": "",
    "text": "Hi there üëã. I am Soumik Rakshit (‡¶∏‡ßå‡¶Æ‡¶ø‡¶ï ‡¶∞‡¶ï‡ßç‡¶∑‡¶ø‡¶§).\nI develop machine learning tools at Weights & Biases.\nYou can learn more about me here."
  },
  {
    "objectID": "posts/depthwise-separable-convolution/index.html",
    "href": "posts/depthwise-separable-convolution/index.html",
    "title": "Depthwise Separable Convolutions in Deep Learning",
    "section": "",
    "text": "The Convolution operation is a widely used function in Functional Analysis, Image Processing Deep Learning. The convolution operation when applied on two functions f and g, produces a third function expressing how the shape of one is modified by the other. While it is immensely popular, especially in the domain of Deep Learning, the vanilla convolution operation is quite expensive computationally. Modern Neural Network architectures such as Xception and MobileNet use a special type of Convolution called Depthwise Separable Convolution to speed up training and inference, especially on Mobile and Embedded Devices."
  },
  {
    "objectID": "posts/depthwise-separable-convolution/index.html#the-vanilla-convolution-operation",
    "href": "posts/depthwise-separable-convolution/index.html#the-vanilla-convolution-operation",
    "title": "Depthwise Separable Convolutions in Deep Learning",
    "section": "The Vanilla Convolution Operation",
    "text": "The Vanilla Convolution Operation\nThe convolution function can be mathematically defined as the following:\n\\[(f \\circledast g)(t) = \\int_{- \\infty}^{\\infty} f(\\tau) g(t - \\tau) d\\tau\\]\nFor all non-negative values of t (i.e, for all values of t such that t ‚àà [0, ‚àû) ), we could truncate the limits of integration resulting in,\n\\[(f \\circledast g)(t) = \\int_{0}^{t} f(\\tau) g(t - \\tau) d\\tau\\]\nIt can also be defined as the overlap of two functions f and g as one slides over the other, performing a sum of products.\n\n\n\n\nSource: https://en.wikipedia.org/wiki/Convolution\n\n\n\n\n\n\n\nConvolution as Sum of Products. Source: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1"
  },
  {
    "objectID": "posts/depthwise-separable-convolution/index.html#computational-complexity-of-convolution",
    "href": "posts/depthwise-separable-convolution/index.html#computational-complexity-of-convolution",
    "title": "Depthwise Separable Convolutions in Deep Learning",
    "section": "Computational Complexity of Convolution",
    "text": "Computational Complexity of Convolution\nIn order to decide the computational complexity of the convolutional operation, we would count the number of multiplication operations for a convolution. This is because the Binary Addition of two numbers may be performed in a single clock cycle using two registers with the inputs latched and a bunch of combinatorial logic gates. Binary multiplication, however, requires successive shift and addition operations which must be performed as many times as there are bits in the multiplier and is thus a more expensive operation.\nLet us consider an input volume of the dimension (\\[D_{V}\\], \\[D_{V}\\], N) where \\[D_{V}\\] is the height and width of the volume and \\[N\\] is the number of channels. In the case of a standard RGB image \\[N = 3\\] and for a gray-scale image \\[N = 1\\].\n\nLet us convolve V with a tensor of shape (\\[D_{V}\\], \\[D_{V}\\], N) or N tensors with the shape (\\[D_{k}\\], \\[D_{k}\\]) which results in a volume \\[G\\] of shape (\\[D_{G}\\], \\[D_{G}\\], N).\n\nLet us count the number of multiplication operations for this operation.\nNumber of multiplication operations for a single stride across a single channel = \\[D_{k} * D_{k}\\].\nFor M channels in the initial volume, the number of multiplication operations = \\[(D_{k})^{2} * M\\].\nSliding the kernel over a volume of (\\[D_{V}\\], \\[D_{V}\\], M), we get a tensor of shape (\\[D_{G}\\], \\[D_{G}\\], N). Hence the total number of multiplication operations for a single channel of the convolution kernel = \\[(D_{G})^{2} * (D_{k})^{2} * M\\].\nSince there are N channels in the convolutional kernel, this operation is repeated N times. Hence, the total number of multiplication operations for the above convolution operation = \\[N * (D_{G})^{2} * (D_{k})^{2} * M\\].\nNow, let us see how using an alternate form of the vanilla convolution operation, we can reduce time complexity."
  },
  {
    "objectID": "posts/depthwise-separable-convolution/index.html#depthwise-separable-convolution",
    "href": "posts/depthwise-separable-convolution/index.html#depthwise-separable-convolution",
    "title": "Depthwise Separable Convolutions in Deep Learning",
    "section": "Depthwise Separable Convolution",
    "text": "Depthwise Separable Convolution\nIn the vanilla convolution operation all, the kernel is applied to all the channels of the input volume. However, Depthwise Separable Convolutions breaks down the whole operation into 2 steps:\n\nDepthwise Convolution or the Filtering Stage\nPointwise Convolution or the Combination Stage\n\n\nDepthwise Convolutions\nLet us consider the same input volume (\\[D_{V}\\], \\[D_{V}\\], M) convolving with M (\\[D_{K}\\], \\[D_{K}\\]) kernels. A single convolution with a single kernel gives a volume of (\\[D_{G}\\], \\[D_{G}\\], 1). Repeating this N times, we get N such tensors and stacking them up channel-wise, we get a single tensor of shape (\\[D_{G}\\], \\[D_{G}\\], M).\n\nNow, the number of multiplication operations for a single kernel convolving over a single input channel = \\[D_{K} * D_{K}\\]. When the convolution is applied over an entire input volume\n\nLet us now find the computational complexity for Depthwise Convolution.\nThe number of multiplication operations for the convolution of a single (\\[D_{K}\\], \\[D_{K}\\]) kernel over a single stride over the input volume = \\[(D_{K})^{2}\\].\nSince the output shape is (\\[D_{G}\\], \\[D_{G}\\]), the number of multiplication operations for convolving over a single channel of the input image = \\[(D_{G})^{2} * (D_{K})^{2}\\].\nSince there are \\[M\\] number of kernels for convolving with \\[M\\] number of channels, the number of multiplication operations for Depthwise Convolution operation = \\[M * (D_{G})^{2} * (D_{K})^{2}\\]."
  },
  {
    "objectID": "posts/depthwise-separable-convolution/index.html#pointwise-convolution",
    "href": "posts/depthwise-separable-convolution/index.html#pointwise-convolution",
    "title": "Depthwise Separable Convolutions in Deep Learning",
    "section": "Pointwise Convolution",
    "text": "Pointwise Convolution\nFor Pointwise Convolution, we convolve the (\\[D_{G}\\], \\[D_{G}\\], M) volume with \\[N\\] kernels of (1, 1, \\[M\\]) producing the desired output of shape (\\[D_{V}\\], \\[D_{V}\\], N).\n\nWe will now find the computational complexity of the Pointwise Convolution operation.\nFor convolving a single kernel over a single stride of the input image, the number of multiplication operations = \\[1 * 1 * M\\] = \\[M\\].\nFor convolving a single kernel over a single channel of the input tensor producing a shape of (\\[D_{G}\\], \\[D_{G}\\]), the number of multiplication operations = \\[M * (D_{G})^{2}\\].\nFor convolving \\[N\\] number of kernels over the whole of input tensor, the number of multiplication operations = \\[N * M * (D_{G})^{2}\\]."
  },
  {
    "objectID": "posts/depthwise-separable-convolution/index.html#comparing-vanilla-convolution-with-depthwise-separable-convolution",
    "href": "posts/depthwise-separable-convolution/index.html#comparing-vanilla-convolution-with-depthwise-separable-convolution",
    "title": "Depthwise Separable Convolutions in Deep Learning",
    "section": "Comparing Vanilla Convolution with Depthwise Separable Convolution",
    "text": "Comparing Vanilla Convolution with Depthwise Separable Convolution\nLet us take the ratios between the Complexity of the Vanilla Convolution () operation and that of the Depthwise Separable Convolution operation.\n\\[\\frac{conv_{vanilla}}{conv_{dsc}} = \\frac{N * (D_{G})^{2} * (D_{K})^{2} * M}{M * (D_{G})^{2} * [(D_{K})^{2} + N]}\\]\nor,\n\\[\\frac{conv_{vanilla}}{conv_{dsc}} = \\frac{(D_{K})^{2} * M}{(D_{K})^{2} + N}\\]\nor,\n\\[\\frac{conv_{vanilla}}{conv_{dsc}} = \\frac{1}{(D_{K})^{2}} + \\frac{1}{N}\\]\nNow, let us consider \\[N = 3\\] and DK = [2 ** i for i in range(5, 11)] and visualize how the ratio varies.\n\nNote that the ratio of Time Complexity of Vanilla Convolution to that of Depthwise Separable Convolution is always much less than 1 and it decreases with increasing Kernel Dimension, making it much faster compared to Vanilla Convolution.\nDepthwise Separable Convolutions are widely used in building fast CNN architectures such as Xception, Mobilenet and Multi-modal Neural Networks. In the upcoming articles, we would discuss these two articles in detail."
  },
  {
    "objectID": "posts/nearest-celebrity-face/index.html",
    "href": "posts/nearest-celebrity-face/index.html",
    "title": "Nearest Celebrity Face using Deep Learning",
    "section": "",
    "text": "Face Recognition is one of the more interesting applications of Deep Learning i. At a single glance, it may seem like a simple classification problem; classify if this photo shows Soumik‚Äôs face or Souranil‚Äôs. You might be quick to jump to the conclusion, oh, the handsome face on the right belongs to Soumik and the ugly face on the left belongs to Souranil but, Ahem!!! We beg to differ.\n\n\n\n\nDear ConvNet, which of these is Soumik and which one is Souranil???\n\n\n\nSee, the problem with traditional ConvNets is that they need to look at lots of images of your face and lots of other faces to learn to correctly classify them; maybe a thousand images from each category. Imagine yourself as the teacher of a class where you want to install a system, which monitors every student and recognize them by faces so that they would not bunk classes (poor students üòì). In order to do so you have to collect 1000 mugshots of each of your students!!! Even if you manage to do this insane task, just imagine having to retrain the model again if a new student decides to join your lecture!!!\nIdeally, we would want to verify the face of a person from any footage given only one photo of the person available in the database. Hence, our challenge, in this case, can be formalized as a One-Shot Learning problem. History has been witness to the fact that Deep Learning algorithms do not work well if you have only one training example."
  },
  {
    "objectID": "posts/nearest-celebrity-face/index.html#face-recognition",
    "href": "posts/nearest-celebrity-face/index.html#face-recognition",
    "title": "Nearest Celebrity Face using Deep Learning",
    "section": "",
    "text": "Face Recognition is one of the more interesting applications of Deep Learning i. At a single glance, it may seem like a simple classification problem; classify if this photo shows Soumik‚Äôs face or Souranil‚Äôs. You might be quick to jump to the conclusion, oh, the handsome face on the right belongs to Soumik and the ugly face on the left belongs to Souranil but, Ahem!!! We beg to differ.\n\n\n\n\nDear ConvNet, which of these is Soumik and which one is Souranil???\n\n\n\nSee, the problem with traditional ConvNets is that they need to look at lots of images of your face and lots of other faces to learn to correctly classify them; maybe a thousand images from each category. Imagine yourself as the teacher of a class where you want to install a system, which monitors every student and recognize them by faces so that they would not bunk classes (poor students üòì). In order to do so you have to collect 1000 mugshots of each of your students!!! Even if you manage to do this insane task, just imagine having to retrain the model again if a new student decides to join your lecture!!!\nIdeally, we would want to verify the face of a person from any footage given only one photo of the person available in the database. Hence, our challenge, in this case, can be formalized as a One-Shot Learning problem. History has been witness to the fact that Deep Learning algorithms do not work well if you have only one training example."
  },
  {
    "objectID": "posts/nearest-celebrity-face/index.html#one-shot-learning",
    "href": "posts/nearest-celebrity-face/index.html#one-shot-learning",
    "title": "Nearest Celebrity Face using Deep Learning",
    "section": "One-Shot Learning",
    "text": "One-Shot Learning\nLet‚Äôs focus a bit more light on the problem discussed earlier with an example. Our dear friend Atul is supposed to appear for a video interview for a company and he wants to remain undisturbed during the interview, so he won‚Äôt allow anyone into his room other than Abhik who speaks a lot of Crox English and would help him with the interview (from behind the laptop of course). So, he wants sets up a system using his phone camera which would verify if the person who wants to enter his room is Abhik or not. Now, Atul can simply design a ConvNet with convolutional layers followed by a couple of fully connected layers ending in a softmax activation with 3 outputs corresponding to the three of us.\n\n\n\n\nWhich of us speaks the best Crox will be decided upon by Atul‚Äôs algorithm!!!\n\n\n\nThere are several demerits to this approach such as\n\nAtul does not have more than thirty of our mugshots which he painfully collected from Facebook and Instagram. Such a small training set would not be enough.\nIf he decides to accept help from Avishek besides Abhik, he would have to retrain the model again (after painfully collecting his mugshots) in order for the algorithm to recognize Avishek also.\n\nSo, in order to make this work, Atul thinks of a different approach. Instead of building a model to differentiate various faces, he decides to build a model that would learn a Similarity Function D. Then that would say how similar the current image is with a mugshot of Abhik that is present in his dataset and he decides upon a similarity threshold œÑ upon meeting which the door will open.\n\nD(image1, image2) = Degree of Difference between the Images D(image1, image2) &lt;= œÑ means images are same, and D(image1, image2) &gt; œÑ means images are different"
  },
  {
    "objectID": "posts/nearest-celebrity-face/index.html#siamese-networks",
    "href": "posts/nearest-celebrity-face/index.html#siamese-networks",
    "title": "Nearest Celebrity Face using Deep Learning",
    "section": "Siamese Networks",
    "text": "Siamese Networks\nThe job of the function D is to learn the level of difference between two different images of faces. A nice way to do this is by using Siamese Networks. While a traditional ConvNet consists of Convolutional layers followed by Fully Connected or Dense Layers which are then fed into a Softmax function to perform classification, in case of a Siamese Network, there is no Softmax unit, instead the last Dense layer acts as the output layers which gives a list or vector of numbers. Let us call the outputs for images x_1 and x_2, f(x_1) and f(x_2) respectively. Let‚Äôs say that the output layer has 128 fully connected units, hence, f(x_1) and f(x_2) will each be a vector of 128 numbers. f(x_1) and f(x_2) are called the Encoding of x_1 and x_2 respectively.\n\nIf we believe the encodings to be a good enough representation of the input images, we can define the function D as the square of norm of the difference between the Encodings.\n\\[D(x_{1}, x_{2}) = ||f(x_{1}) - f(x_{2})||^{2}\\]\nNow the question comes that how do we train such a network. Since the same network is used to compute the Encodings from two different images, we have to train the parameters so that the trained network defines as accurate Encoding."
  },
  {
    "objectID": "posts/nearest-celebrity-face/index.html#training-a-siamese-network",
    "href": "posts/nearest-celebrity-face/index.html#training-a-siamese-network",
    "title": "Nearest Celebrity Face using Deep Learning",
    "section": "Training a Siamese Network",
    "text": "Training a Siamese Network\nOne way to learn the parameters of the neural network so that it gives you an accurate enough encoding for the images is to define an applied gradient descent on the Triplet Loss Function. In this case, we will have an anchor image, a positive image (the same person as the anchor image) and a negative image (a different person from the anchor image). Now we train the Siamese Network so that the distance between the anchor and the positive image is minimized. This also increases the distance between the anchor and the negative image is maximized. The fact that at each instance, we are looking at three images gives rise to the terminology Triplet Loss. The dataset, in this case, should consist of multiple triplets of Anchor, Positive and Negative Images."
  },
  {
    "objectID": "posts/nearest-celebrity-face/index.html#learning-objective",
    "href": "posts/nearest-celebrity-face/index.html#learning-objective",
    "title": "Nearest Celebrity Face using Deep Learning",
    "section": "Learning Objective",
    "text": "Learning Objective\nFor Positive Image,\n\\[D(A, P) = ||f(A) - f(P)||^{2}\\]\nFor Negative Image,\n\\[D(A, N) = ||f(A) - f(N)||^{2}\\]\nLearning Objective is\n\\[D(A, P) - D(A, N) + \\alpha \\leq 0\\]\nwhere Œ± is defined as a margin and the Loss Function is given as\n\\[loss = \\sum_{i=1}^{n} max(||f(A_{i}) - f(P_{i})||^{2} - ||f(A_{i}) - f(P_{i})||^{2} + \\alpha, 0)\\]\nwhere n is the number of triplets in the dataset.\nAll the ideas till this point have been presented in the paper FaceNet by Florian Schroff, Dmitry Kalinichenko, and James Philbin.\nAfter having trained the FaceNet on a large Triplet Dataset, we can use it to verify any face. Now, Atul would only need to store the Encodings of the faces of Abhik and Avishek. Then he would have to decide upon the value of Similarity Threshold œÑ. Whenever someone approaches the door, his face will be localized and passed through the FaceNet. If their D value is less than œÑ then it is a match!!!"
  },
  {
    "objectID": "posts/nearest-celebrity-face/index.html#extending-the-idea-to-nearest-celebrity-face",
    "href": "posts/nearest-celebrity-face/index.html#extending-the-idea-to-nearest-celebrity-face",
    "title": "Nearest Celebrity Face using Deep Learning",
    "section": "Extending the Idea to Nearest Celebrity Face",
    "text": "Extending the Idea to Nearest Celebrity Face\nI always wondered about those Facebook applications which used to predict stuff like which Celebrity or Footballer you look like. I tried building a similar application using the idea of FaceNet. Instead of keeping images of existing people to be verified in the database, I collected images of famous celebrities from Google Images, closely cropped their faces and stored their Encodings in the database. The Encodings were generated by a pre-trained FaceNet with an Inception backbone. Now theoretically, if I input some of my friends‚Äô faces, they should ideally match the closest image in the database. Well, I tried implementing it and the results were hilarious üòÇ\n    \nThe project can be found at https://github.com/soumik12345/Nearest-Celebrity-Face. If you like the project and found the results to be hilarious, please leave a star on the Github repository. For more such exciting articles, stay tuned at http://geekyrakshit.dev."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "About Me\nI am generally interested in the field of computer vision, particularly in foundation models for computer vision, generative models for images, implicit representation and representation learning.\nI work on developing tools for Machine Learning parctioners at Weights & Biases. My day-to-day tasks include\n\ndeveloping and maintaining integrations with open-source libraries such as keras, ultralytics, super-gradients, kaolin-wisp, etc.\nprototyping experimental tools in the Weights & Biases ecosystem as part of wandb-addons.\nwriting exciting and beautiful blog posts on machine learning using W&B Reports."
  }
]