<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Geekyrakshit</title>
<link>https://geekyrakshit.dev/wandb_reports.html</link>
<atom:link href="https://geekyrakshit.dev/wandb_reports.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Wed, 28 Sep 2022 18:30:00 GMT</lastBuildDate>
<item>
  <title>Improving Generative Images with Instructions: Prompt-to-Prompt Image Editing with Cross Attention Control</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/cross-attention-control.html</link>
  <description><![CDATA[ 



<details>
<summary>
<strong> Featured on <a href="https://www.youtube.com/@TwoMinutePapers">Two Minute Papers</a> </strong>
</summary>
<br> <iframe width="560" height="315" src="https://www.youtube.com/embed/XW_nO2NMH_g?si=OAaFHjcpu2jHIdU-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</details>

<iframe src="https://wandb.ai/wandb/cross-attention-control/reports/Improving-Generative-Images-with-Instructions-Prompt-to-Prompt-Image-Editing-with-Cross-Attention-Control--VmlldzoyNjk2MDAy?galleryTag=stable-diffusion" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>generative</category>
  <category>stable-diffusion</category>
  <category>2-minute-papers</category>
  <guid>https://geekyrakshit.dev/reports/cross-attention-control.html</guid>
  <pubDate>Wed, 28 Sep 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/cross-attention-control.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Building Diverse Skillsets for Video Game Characters With Adversarial Skill Embeddings</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/game-characters.html</link>
  <description><![CDATA[ 



<details>
<summary>
<strong> Featured on <a href="https://www.youtube.com/@TwoMinutePapers">Two Minute Papers</a> </strong>
</summary>
<br> <iframe width="560" height="315" src="https://www.youtube.com/embed/1kV-rZZw50Q?si=WZmPeihHTqZMwHLc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</details>
<iframe src="https://wandb.ai/geekyrakshit/adversarial%20skill%20embeddings/reports/Building-Diverse-Skillsets-for-Video-Game-Characters-With-Adversarial-Skill-Embeddings--VmlldzoyMjc3OTU5?galleryTag=computer-vision" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>reinforcement-learning</category>
  <category>2-minute-papers</category>
  <guid>https://geekyrakshit.dev/reports/game-characters.html</guid>
  <pubDate>Mon, 18 Jul 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/game-characters.png" medium="image" type="image/png" height="121" width="144"/>
</item>
<item>
  <title>Robotic Telekinesis in the Wild</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/robotic-telekinesis.html</link>
  <description><![CDATA[ 



<details>
<summary>
<strong> Featured on <a href="https://www.youtube.com/@TwoMinutePapers">Two Minute Papers</a> </strong>
</summary>
<br> <iframe width="560" height="315" src="https://www.youtube.com/embed/fVrcBY0lOWw?si=hcJo5CaGlWHeyMpA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</details>
<iframe src="https://wandb.ai/geekyrakshit/robotic-telekinesis/reports/Robotic-Telekinesis-in-the-Wild--VmlldzoyMjY1NDAw" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>robotics</category>
  <category>2-minute-papers</category>
  <guid>https://geekyrakshit.dev/reports/robotic-telekinesis.html</guid>
  <pubDate>Mon, 11 Jul 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/robotic-telekinesis.png" medium="image" type="image/png" height="69" width="144"/>
</item>
<item>
  <title>Digging Into StyleGAN-NADA for CLIP-Guided Domain Adaptation</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/stylegan-nada.html</link>
  <description><![CDATA[ 



<details>
<summary>
<strong> Featured on <a href="https://www.youtube.com/@TwoMinutePapers">Two Minute Papers</a> </strong>
</summary>
<br> <iframe width="560" height="315" src="https://www.youtube.com/embed/MO2K0JXAedM?si=SQ8fY8rA9cjTPOmz" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</details>
<iframe src="https://wandb.ai/geekyrakshit/stylegan-nada/reports/Digging-Into-StyleGAN-NADA-for-CLIP-Guided-Domain-Adaptation--VmlldzoyMjA5MDU1" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>generative</category>
  <category>2-minute-papers</category>
  <guid>https://geekyrakshit.dev/reports/stylegan-nada.html</guid>
  <pubDate>Thu, 07 Jul 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/nada.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Modern Evolution Strategies for Creativity</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/modern-evolution-strategies.html</link>
  <description><![CDATA[ 



<iframe src="https://wandb.ai/geekyrakshit/es-clip/reports/Modern-Evolution-Strategies-for-Creativity--VmlldzoyMDU3NTQ2?galleryTag=tmp" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>generative</category>
  <category>jax</category>
  <guid>https://geekyrakshit.dev/reports/modern-evolution-strategies.html</guid>
  <pubDate>Sat, 30 Apr 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/modern-evolution-startegies.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/mip-nerf-360.html</link>
  <description><![CDATA[ 



<iframe src="https://wandb.ai/geekyrakshit/mip-nerf-360/reports/Mip-NeRF-360-Unbounded-Anti-Aliased-Neural-Radiance-Fields--VmlldzoxOTc4Mjk4" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>nerf</category>
  <guid>https://geekyrakshit.dev/reports/mip-nerf-360.html</guid>
  <pubDate>Fri, 29 Apr 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/mip-nerf-360.png" medium="image" type="image/png" height="88" width="144"/>
</item>
<item>
  <title>Extracting Triangular 3D Models, Materials, and Lighting From Images</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/extracting-triangular-models.html</link>
  <description><![CDATA[ 



<details>
<summary>
<strong> Featured on <a href="https://www.youtube.com/@TwoMinutePapers">Two Minute Papers</a> </strong>
</summary>
<br> <iframe width="560" height="315" src="https://www.youtube.com/embed/yl1jkmF7Xug?si=NUPd2T7bJqJFo0cU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</details>
<iframe src="https://wandb.ai/geekyrakshit/Extracting%20Triangular%203D%20Models/reports/Extracting-Triangular-3D-Models-Materials-and-Lighting-From-Images--VmlldzoxOTQ2MDEy" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>graphics</category>
  <category>2-minute-papers</category>
  <guid>https://geekyrakshit.dev/reports/extracting-triangular-models.html</guid>
  <pubDate>Mon, 25 Apr 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/extracting-triangular-models.png" medium="image" type="image/png" height="143" width="144"/>
</item>
<item>
  <title>Barbershop: Hair Transfer with GAN-Based Image Compositing Using Segmentation Masks</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/barbershop.html</link>
  <description><![CDATA[ 



<details>
<summary>
<strong> Featured on <a href="https://www.youtube.com/@TwoMinutePapers">Two Minute Papers</a> </strong>
</summary>
<br> <iframe width="560" height="315" src="https://www.youtube.com/embed/YNY_ZEuDncM?si=yCmERafJmazBNaYm" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</details>
<iframe src="https://wandb.ai/geekyrakshit/barbershop/reports/Barbershop-Hair-Transfer-with-GAN-Based-Image-Compositing-Using-Segmentation-Masks--VmlldzoxNzk0OTY3" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>generative</category>
  <category>2-minute-papers</category>
  <guid>https://geekyrakshit.dev/reports/barbershop.html</guid>
  <pubDate>Sun, 17 Apr 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/barbershop.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Block-NeRF: Scalable Large Scene Neural View Synthesis</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/block-nerf.html</link>
  <description><![CDATA[ 



<details>
<summary>
<strong> Featured on <a href="https://www.youtube.com/@TwoMinutePapers">Two Minute Papers</a> </strong>
</summary>
<br> <iframe width="560" height="315" src="https://www.youtube.com/embed/8AZhcnWOK7M?si=71EcyK15MsnwdS2w" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</details>
<iframe src="https://wandb.ai/geekyrakshit/block-nerf/reports/Block-NeRF-Scalable-Large-Scene-Neural-View-Synthesis--VmlldzoxNjIyMzI4?galleryTag=tmp" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>nerf</category>
  <category>2-minute-papers</category>
  <guid>https://geekyrakshit.dev/reports/block-nerf.html</guid>
  <pubDate>Sun, 13 Mar 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/block-nerf.png" medium="image" type="image/png" height="108" width="144"/>
</item>
<item>
  <title>Learning Robust Perceptive Locomotion for Quadrupedal Robots in the Wild</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/robust-perceptive-locomotive.html</link>
  <description><![CDATA[ 



<details>
<summary>
<strong> Featured on <a href="https://www.youtube.com/@TwoMinutePapers">Two Minute Papers</a> </strong>
</summary>
<br> <iframe width="560" height="315" src="https://www.youtube.com/embed/XM-rKTOyD_k?si=U4Lh9e3Fzzhm-gIW" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</details>
<iframe src="https://wandb.ai/geekyrakshit/robust-perception-locomotion/reports/Learning-Robust-Perceptive-Locomotion-for-Quadrupedal-Robots-in-the-Wild--VmlldzoxNjI0NjUy" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>reinforcement-learning</category>
  <category>robotics</category>
  <category>2-minute-papers</category>
  <guid>https://geekyrakshit.dev/reports/robust-perceptive-locomotive.html</guid>
  <pubDate>Thu, 10 Mar 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/robust-perceptive-locomotive.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>PoE-GAN: Generating Images from Multi-Modal Inputs</title>
  <dc:creator>[GeekyRakshit](../../) </dc:creator>
  <link>https://geekyrakshit.dev/reports/poe-gan.html</link>
  <description><![CDATA[ 



<details>
<summary>
<strong> Featured on <a href="https://www.youtube.com/@TwoMinutePapers">Two Minute Papers</a> </strong>
</summary>
<br> <iframe width="560" height="315" src="https://www.youtube.com/embed/eaSTGOgO-ss?si=BokCt8OKvPcyqMPS" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</details>
<iframe src="https://wandb.ai/geekyrakshit/poegan/reports/PoE-GAN-Generating-Images-from-Multi-Modal-Inputs--VmlldzoxNTA5MzUx" style="border:none;height:1024px;width:100%">
</iframe>



 ]]></description>
  <category>computervision</category>
  <category>deeplearning</category>
  <category>generative</category>
  <category>2-minute-papers</category>
  <guid>https://geekyrakshit.dev/reports/poe-gan.html</guid>
  <pubDate>Thu, 24 Feb 2022 18:30:00 GMT</pubDate>
  <media:content url="https://geekyrakshit.dev/reports/assets/poe-gan-banner.png" medium="image" type="image/png" height="144" width="144"/>
</item>
</channel>
</rss>
